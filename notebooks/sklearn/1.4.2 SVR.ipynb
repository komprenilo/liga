{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d1db70-b03b-4225-b915-9bd7b7d36536",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/1.1/modules/svm.html#regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b9e55-70e6-4c32-9c99-caa8f1aa3660",
   "metadata": {},
   "source": [
    "## Traning and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afd5aa9-9da0-484b-b50a-6e24637b9b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be6782a-f115-4182-ac26-ef9c0d4f2e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
       "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613]),\n",
       " 151.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324d5e22-cd46-4d24-b246-dd1c7c7853f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
       "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405]),\n",
       " 75.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[1], y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b40a740-e8d1-4dd8-91a3-13c8dd6fcb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/da/.cache/pants/named_caches/pex_root/venvs/97296c1a2aa5705046eb53ad742c9a9d598e9ce1/3a466fe3d02679c1e38c4c1cbe108770bca9adb4/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2022/11/15 23:34:31 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Registered model 'da_svr' already exists. Creating a new version of this model...\n",
      "2022/11/15 23:34:31 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: da_svr, version 11\n",
      "Created version '11' of model 'da_svr'.\n",
      "/Users/da/.cache/pants/named_caches/pex_root/venvs/97296c1a2aa5705046eb53ad742c9a9d598e9ce1/3a466fe3d02679c1e38c4c1cbe108770bca9adb4/lib/python3.8/site-packages/rikai/spark/sql/codegen/mlflow_logger.py:183: UserWarning: value of rikai.output.schema is None or empty and will not be populated to MLflow\n",
      "  warnings.warn(\n",
      "2022/11/15 23:34:32 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Registered model 'da_nusvr' already exists. Creating a new version of this model...\n",
      "2022/11/15 23:34:33 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: da_nusvr, version 8\n",
      "Created version '8' of model 'da_nusvr'.\n",
      "2022/11/15 23:34:34 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Registered model 'da_linear_svr' already exists. Creating a new version of this model...\n",
      "2022/11/15 23:34:34 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: da_linear_svr, version 8\n",
      "Created version '8' of model 'da_linear_svr'.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "import mlflow\n",
    "from rikai_sklearn.mlflow import log_model\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "mlflow_tracking_uri = \"sqlite:///mlruns.db\"\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "# train a model\n",
    "with mlflow.start_run() as run:\n",
    "    ####\n",
    "    # Part 1: Train the model and register it on MLflow\n",
    "    ####\n",
    "    \n",
    "    model_svr = svm.SVR(epsilon=0.3).fit(X, y)\n",
    "    model_nusvr = svm.NuSVR().fit(X, y)\n",
    "    model_l_svr = svm.LinearSVR().fit(X, y)\n",
    "    \n",
    "    svr_name = f\"{getpass.getuser()}_svr\"\n",
    "    nusvr_name = f\"{getpass.getuser()}_nusvr\"\n",
    "    l_svr_name = f\"{getpass.getuser()}_linear_svr\"\n",
    "    \n",
    "    log_model(model_svr, registered_model_name=svr_name)\n",
    "    log_model(model_nusvr, registered_model_name=nusvr_name)\n",
    "    log_model(model_l_svr, registered_model_name=l_svr_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad1843-8e9b-4dc5-89ac-892ee670a740",
   "metadata": {},
   "source": [
    "## Apply the model on the large scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73eb3f5-c3f8-47d1-9e3d-04da4ca39e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/da/.cache/pants/named_caches/pex_root/installed_wheels/fcaa57f02b90be772d50778078fc41c3660d5a6c43218e45b2c2aef2ec8e9d58/pyspark-3.2.2-py2.py3-none-any.whl/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/da/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/da/.ivy2/jars\n",
      "ai.eto#rikai_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-73ddfb5f-6827-40cb-a91e-eadf65a6e33d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound ai.eto#rikai_2.12;0.1.14 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound com.typesafe.scala-logging#scala-logging_2.12;3.9.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in spark-list\n",
      "\tfound org.mlflow#mlflow-client;1.21.0 in central\n",
      "\tfound org.apache.logging.log4j#log4j-core;2.17.1 in central\n",
      ":: resolution report :: resolve 216ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tai.eto#rikai_2.12;0.1.14 from central in [default]\n",
      "\tcom.typesafe.scala-logging#scala-logging_2.12;3.9.4 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-core;2.17.1 from central in [default]\n",
      "\torg.mlflow#mlflow-client;1.21.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from spark-list in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.slf4j#slf4j-api;1.7.25 by [org.slf4j#slf4j-api;1.7.30] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   7   |   0   |   0   |   1   ||   6   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-73ddfb5f-6827-40cb-a91e-eadf65a6e33d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 6 already retrieved (0kB/8ms)\n",
      "22/11/15 23:34:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/11/15 23:34:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/11/15 23:34:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/11/15 23:34:37 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------------------+-------+\n",
      "|name |flavor|uri                    |options|\n",
      "+-----+------+-----------------------+-------+\n",
      "|svr  |      |mlflow:///da_svr       |       |\n",
      "|nusvr|      |mlflow:///da_nusvr     |       |\n",
      "|l_svr|      |mlflow:///da_linear_svr|       |\n",
      "+-----+------+-----------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from example import spark\n",
    "from rikai.spark.sql.codegen.mlflow_logger import CONF_MLFLOW_TRACKING_URI\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")\n",
    "spark.conf.set(CONF_MLFLOW_TRACKING_URI, mlflow_tracking_uri)\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE MODEL svr USING 'mlflow:///{svr_name}';\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE MODEL nusvr USING 'mlflow:///{nusvr_name}';\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE MODEL l_svr USING 'mlflow:///{l_svr_name}';\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "spark.sql(\"show models\").show(10, vertical=False, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658686cb-a5db-4dcf-ac34-4323d00b36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- svr: float (nullable = true)\n",
      " |-- nusvr: float (nullable = true)\n",
      " |-- l_svr: float (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svr</th>\n",
       "      <th>nusvr</th>\n",
       "      <th>l_svr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109.949249</td>\n",
       "      <td>109.949249</td>\n",
       "      <td>109.949249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          svr       nusvr       l_svr\n",
       "0  109.949249  109.949249  109.949249"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = spark.sql(f\"\"\"\n",
    "select\n",
    "  ML_PREDICT(svr, array(0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
    "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613)) as svr,\n",
    "  ML_PREDICT(nusvr, array(0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
    "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613)) as nusvr,\n",
    "  ML_PREDICT(l_svr, array(0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
    "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613)) as l_svr\n",
    "        \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "result.printSchema()\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d20ae5-6b4b-448b-8f21-0a26dc72330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.219246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          svr\n",
       "0  106.219246"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "select\n",
    "  ML_PREDICT(svr, array(-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
    "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405)) as svr\n",
    "\"\"\"\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df9f3f4-e79e-4b32-bb85-e94ad78500ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nusvr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.219246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nusvr\n",
       "0  106.219246"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "select  ML_PREDICT(nusvr, array(-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
    "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405)) as nusvr\n",
    "\"\"\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77987f10-9215-492b-acd0-3243ce6ac294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_svr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.219246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        l_svr\n",
       "0  106.219246"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select ML_PREDICT(l_svr, array(-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
    "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405)) as l_svr\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbe16a-c846-4ac3-bff2-673c846cd6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
