{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d1db70-b03b-4225-b915-9bd7b7d36536",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/1.1/modules/svm.html#regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b9e55-70e6-4c32-9c99-caa8f1aa3660",
   "metadata": {},
   "source": [
    "## Traning and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afd5aa9-9da0-484b-b50a-6e24637b9b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be6782a-f115-4182-ac26-ef9c0d4f2e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
       "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613]),\n",
       " 151.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324d5e22-cd46-4d24-b246-dd1c7c7853f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
       "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405]),\n",
       " 75.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[1], y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b40a740-e8d1-4dd8-91a3-13c8dd6fcb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da/.cache/pants/named_caches/pex_root/venvs/d6a7829465a74d6f7ee1c45b5eb7d6677ce27680/cc443c29ee413022004e366aaeb20446296388d4/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2023/01/06 11:12:49 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Successfully registered model 'da_svr'.\n",
      "2023/01/06 11:12:50 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: da_svr, version 1\n",
      "Created version '1' of model 'da_svr'.\n",
      "/tmp/pants-sandbox-iNPSq8/python/rikai/spark/sql/codegen/mlflow_logger.py:144: UserWarning: value of rikai.output.schema is None or empty and will not be populated to MLflow\n",
      "  warnings.warn(\n",
      "2023/01/06 11:12:53 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Successfully registered model 'da_nusvr'.\n",
      "2023/01/06 11:12:54 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: da_nusvr, version 1\n",
      "Created version '1' of model 'da_nusvr'.\n",
      "2023/01/06 11:12:56 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Successfully registered model 'da_linear_svr'.\n",
      "2023/01/06 11:12:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: da_linear_svr, version 1\n",
      "Created version '1' of model 'da_linear_svr'.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "import mlflow\n",
    "from liga.sklearn.mlflow import log_model\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "mlflow_tracking_uri = \"sqlite:///mlruns.db\"\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "# train a model\n",
    "with mlflow.start_run() as run:\n",
    "    ####\n",
    "    # Part 1: Train the model and register it on MLflow\n",
    "    ####\n",
    "    \n",
    "    model_svr = svm.SVR(epsilon=0.3).fit(X, y)\n",
    "    model_nusvr = svm.NuSVR().fit(X, y)\n",
    "    model_l_svr = svm.LinearSVR().fit(X, y)\n",
    "    \n",
    "    svr_name = f\"{getpass.getuser()}_svr\"\n",
    "    nusvr_name = f\"{getpass.getuser()}_nusvr\"\n",
    "    l_svr_name = f\"{getpass.getuser()}_linear_svr\"\n",
    "    \n",
    "    log_model(model_svr, registered_model_name=svr_name)\n",
    "    log_model(model_nusvr, registered_model_name=nusvr_name)\n",
    "    log_model(model_l_svr, registered_model_name=l_svr_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad1843-8e9b-4dc5-89ac-892ee670a740",
   "metadata": {},
   "source": [
    "## Apply the model on the large scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73eb3f5-c3f8-47d1-9e3d-04da4ca39e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/06 11:12:58 WARN Utils: Your hostname, debian resolves to a loopback address: 127.0.1.1; using 192.168.31.194 instead (on interface wlx1cbfce3ffbfe)\n",
      "23/01/06 11:12:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/da/.cache/pants/named_caches/pex_root/installed_wheels/8f254bc20b539246427b2913639b8a0258db76ab54ba91fbbebb8dc8c36183c1/pyspark-3.3.1-py2.py3-none-any.whl/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/da/.ivy2/cache\n",
      "The jars for the packages stored in: /home/da/.ivy2/jars\n",
      "ai.eto#rikai_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5705bbf0-cfb4-4f08-93c5-a85e6c849c73;1.0\n",
      "\tconfs: [default]\n",
      "\tfound ai.eto#rikai_2.12;0.2.0-SNAPSHOT in local-ivy-cache\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound com.typesafe.scala-logging#scala-logging_2.12;3.9.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in spark-list\n",
      "\tfound org.mlflow#mlflow-client;1.21.0 in central\n",
      "\tfound org.apache.logging.log4j#log4j-core;2.17.1 in central\n",
      ":: resolution report :: resolve 290ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tai.eto#rikai_2.12;0.2.0-SNAPSHOT from local-ivy-cache in [default]\n",
      "\tcom.typesafe.scala-logging#scala-logging_2.12;3.9.4 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-core;2.17.1 from central in [default]\n",
      "\torg.mlflow#mlflow-client;1.21.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from spark-list in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.slf4j#slf4j-api;1.7.25 by [org.slf4j#slf4j-api;1.7.30] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   7   |   0   |   0   |   1   ||   7   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5705bbf0-cfb4-4f08-93c5-a85e6c849c73\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 7 already retrieved (0kB/12ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/06 11:13:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n",
      "23/01/06 11:13:06 WARN Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.\n",
      "23/01/06 11:13:06 WARN SparkContext: The path file:///home/da/.ivy2/jars/ai.eto_rikai_2.12-0.2.0-SNAPSHOT.jar has been added already. Overwriting of added paths is not supported in the current version.\n",
      "+-----+------+-----------------------+-------+\n",
      "|name |flavor|uri                    |options|\n",
      "+-----+------+-----------------------+-------+\n",
      "|svr  |      |mlflow:///da_svr       |       |\n",
      "|nusvr|      |mlflow:///da_nusvr     |       |\n",
      "|l_svr|      |mlflow:///da_linear_svr|       |\n",
      "+-----+------+-----------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from example import spark\n",
    "from rikai.spark.sql.codegen.mlflow_logger import CONF_MLFLOW_TRACKING_URI\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")\n",
    "spark.conf.set(CONF_MLFLOW_TRACKING_URI, mlflow_tracking_uri)\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE MODEL svr USING 'mlflow:///{svr_name}';\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE MODEL nusvr USING 'mlflow:///{nusvr_name}';\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE MODEL l_svr USING 'mlflow:///{l_svr_name}';\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "spark.sql(\"show models\").show(10, vertical=False, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658686cb-a5db-4dcf-ac34-4323d00b36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- svr: float (nullable = true)\n",
      " |-- nusvr: float (nullable = true)\n",
      " |-- l_svr: float (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svr</th>\n",
       "      <th>nusvr</th>\n",
       "      <th>l_svr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.488663</td>\n",
       "      <td>110.488663</td>\n",
       "      <td>110.488663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          svr       nusvr       l_svr\n",
       "0  110.488663  110.488663  110.488663"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = spark.sql(f\"\"\"\n",
    "select\n",
    "  ML_PREDICT(svr, array(0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
    "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613)) as svr,\n",
    "  ML_PREDICT(nusvr, array(0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
    "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613)) as nusvr,\n",
    "  ML_PREDICT(l_svr, array(0.03807591,  0.05068012,  0.06169621,  0.02187239, -0.0442235 ,\n",
    "        -0.03482076, -0.04340085, -0.00259226,  0.01990749, -0.01764613)) as l_svr\n",
    "        \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "result.printSchema()\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d20ae5-6b4b-448b-8f21-0a26dc72330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.738571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          svr\n",
       "0  106.738571"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "select\n",
    "  ML_PREDICT(svr, array(-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
    "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405)) as svr\n",
    "\"\"\"\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df9f3f4-e79e-4b32-bb85-e94ad78500ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nusvr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.738571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nusvr\n",
       "0  106.738571"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "select  ML_PREDICT(nusvr, array(-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
    "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405)) as nusvr\n",
    "\"\"\").toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77987f10-9215-492b-acd0-3243ce6ac294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_svr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.738571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        l_svr\n",
       "0  106.738571"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select ML_PREDICT(l_svr, array(-0.00188202, -0.04464164, -0.05147406, -0.02632753, -0.00844872,\n",
    "        -0.01916334,  0.07441156, -0.03949338, -0.06833155, -0.09220405)) as l_svr\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbe16a-c846-4ac3-bff2-673c846cd6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
